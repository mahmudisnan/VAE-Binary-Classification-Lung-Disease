{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b18acb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2202341086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2307410255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2302394915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2408458946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306409371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2402436028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>2402436030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>2402436038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>2402436122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2402436133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  class_id\n",
       "0    2202341086         1\n",
       "1    2307410255         1\n",
       "2    2302394915         1\n",
       "3    2408458946         1\n",
       "4    2306409371         1\n",
       "..          ...       ...\n",
       "791  2402436028         0\n",
       "792  2402436030         0\n",
       "793  2402436038         0\n",
       "794  2402436122         0\n",
       "795  2402436133         1\n",
       "\n",
       "[796 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"Chest/ChestNew/trainfiltered.csv\"\n",
    "test_path = \"Chest/ChestNew/testfiltered.csv\"\n",
    "image_folder = \"Chest/ChestNew/\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "train_df = train_df[[\"Name\", \"class_id\"]]\n",
    "test_df = test_df[[\"Name\", \"class_id\"]]\n",
    "\n",
    "\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a6bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_folder, transform_aug=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform_aug = transform_aug\n",
    "        self.raw_tensor = T.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.loc[idx, \"Name\"]\n",
    "        label = int(self.dataframe.loc[idx, \"class_id\"])\n",
    "\n",
    "        # Full path ke gambar\n",
    "        img_path = os.path.join(self.image_folder, str(img_name) + \".png\")\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "            image = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
    "\n",
    "        x_input, x_raw = self.transform_aug(image)\n",
    "\n",
    "        return x_input, x_raw, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f00d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BDSRC\\miniconda3\\envs\\ViTlung\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class CombinedAugmentation:\n",
    "    def __init__(self):\n",
    "        self.albumentations_transform = A.Compose([\n",
    "            A.Resize(224, 224),\\\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.8),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.GaussNoise(var_limit=(5.0, 20.0), p=0.5),\n",
    "            A.MotionBlur(p=0.2)\n",
    "            \n",
    "        ])\n",
    "\n",
    "        self.norm = A.Normalize(mean=(0.5,), \n",
    "                                std=(0.5,))\n",
    "        \n",
    "        self.to_tensor = ToTensorV2()\n",
    "\n",
    "        self.torch_transform = T.Compose([\n",
    "            # Augmentasi tambahan setelah tensor (opsional)\n",
    "            T.RandomErasing(p=0.3, scale=(0.02, 0.2))\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img_pil):\n",
    "        img = np.array(img_pil)\n",
    "\n",
    "        augmented = self.albumentations_transform(image=img)['image']\n",
    "\n",
    "        img_raw = T.ToTensor()(Image.fromarray(augmented))\n",
    "\n",
    "        normed = self.norm(image=augmented)['image']\n",
    "\n",
    "        tensor_normed = self.to_tensor(image=normed)['image']\n",
    "        \n",
    "        return tensor_normed, img_raw\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d35d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BDSRC\\miniconda3\\envs\\ViTlung\\Lib\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_15396\\961393361.py:18: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5.0, 20.0), p=0.5),\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi transform gabungan\n",
    "train_transform = CombinedAugmentation()\n",
    "\n",
    "# Dataset & Dataloader\n",
    "train_dataset = ChestXrayDataset(train_df, image_folder, transform_aug=train_transform)\n",
    "test_dataset = ChestXrayDataset(test_df, image_folder, transform_aug=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7983a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class VAE_Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim=64, num_classes=2, input_size=(3, 224, 224)):\n",
    "        super(VAE_Classifier, self).__init__()\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.encoder_local = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1\n",
    "        )\n",
    "\n",
    "        self.encoder_global = nn.Sequential(\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4\n",
    "        )\n",
    "\n",
    "        self.pool_local = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.pool_global = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Hitung flatten_dim secara dinamis\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_size)\n",
    "            local_out = self.encoder_local(dummy_input)\n",
    "            global_out = self.encoder_global(local_out)\n",
    "\n",
    "            pooled_local = self.pool_local(local_out)\n",
    "            pooled_global = self.pool_global(global_out)\n",
    "\n",
    "            flat_local = torch.flatten(pooled_local, start_dim=1)\n",
    "            flat_global = torch.flatten(pooled_global, start_dim=1)\n",
    "\n",
    "            self.flatten_dim = flat_local.shape[1] + flat_global.shape[1] \n",
    "            self.decoder_input_shape = pooled_global.shape[1:]  # (C, H, W)\n",
    "\n",
    "        print(f\"flatten_dim: {self.flatten_dim}\")\n",
    "\n",
    "        # Encoder output ke latent space\n",
    "        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)\n",
    "\n",
    "        # Decoder dari latent ke feature map\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 512 * 7 * 7)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, (512, 7, 7)),\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "        # Classifier dari latent space\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar, deterministic=False):\n",
    "        if deterministic:\n",
    "            return mu\n",
    "        else:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "\n",
    "    def forward(self, x, deterministic=False):\n",
    "        x_local = self.encoder_local(x)\n",
    "        x_global = self.encoder_global(x_local)\n",
    "\n",
    "        pooled_local = self.pool_local(x_local)\n",
    "        pooled_global = self.pool_global(x_global)\n",
    "\n",
    "        flat_local = torch.flatten(pooled_local, start_dim=1)\n",
    "        flat_global = torch.flatten(pooled_global, start_dim=1)\n",
    "\n",
    "        x_flat = torch.cat([flat_local, flat_global], dim=1)\n",
    "\n",
    "        mu = self.fc_mu(x_flat)\n",
    "        logvar = self.fc_logvar(x_flat)\n",
    "        logvar = torch.clamp(logvar, min=-10, max=10)\n",
    "\n",
    "        z = self.reparameterize(mu, logvar, deterministic=deterministic)\n",
    "        \n",
    "        x_recon = self.decoder_fc(z)\n",
    "        x_recon = self.decoder(x_recon)\n",
    "        y_pred = self.classifier(z)\n",
    "        \n",
    "        return x_recon, mu, logvar, y_pred\n",
    "\n",
    "def loss_function(x_recon, x, mu, logvar, y_pred, y_true, alpha=1.0, beta=0.0001, gamma=2.0):\n",
    "    recon_loss = nn.functional.mse_loss(x_recon, x, reduction='mean')\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()) \n",
    "    class_loss = nn.functional.cross_entropy(y_pred, y_true)\n",
    "    \n",
    "    # Debug print (aktifkan sementara)\n",
    "    print(f\"recon: {recon_loss.item():.4f}, kl: {kl_loss.item():.4f}, cls: {class_loss.item():.4f}\")\n",
    "    \n",
    "    return alpha * recon_loss + beta * kl_loss + gamma * class_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957819d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahmudisnan18\u001b[0m (\u001b[33mmahmudisnan18-binus-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\BDSRC\\Documents\\Mahmud\\wandb\\run-20250511_170910-vudivok9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung/runs/vudivok9' target=\"_blank\">vae_resnet50_run1</a></strong> to <a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung' target=\"_blank\">https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung/runs/vudivok9' target=\"_blank\">https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung/runs/vudivok9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\BDSRC/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:08<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_dim: 2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:32<00:00,  3.71s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:22<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/200\n",
      "Train Loss: 1.4842, Accuracy: 0.5176\n",
      "Val   Loss: 1.3326, Accuracy: 0.6800, F1: 0.6736\n",
      "✅ Best model saved at epoch 1 with F1: 0.6736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:36<00:00,  3.85s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:27<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/200\n",
      "Train Loss: 1.4159, Accuracy: 0.5603\n",
      "Val   Loss: 1.3752, Accuracy: 0.5650, F1: 0.4893\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:55<00:00,  4.62s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/200\n",
      "Train Loss: 1.3857, Accuracy: 0.5817\n",
      "Val   Loss: 1.3215, Accuracy: 0.6800, F1: 0.6637\n",
      "No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:55<00:00,  4.64s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/200\n",
      "Train Loss: 1.3502, Accuracy: 0.6131\n",
      "Val   Loss: 1.3147, Accuracy: 0.6950, F1: 0.6842\n",
      "✅ Best model saved at epoch 4 with F1: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:55<00:00,  4.61s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/200\n",
      "Train Loss: 1.3365, Accuracy: 0.6256\n",
      "Val   Loss: 1.3035, Accuracy: 0.6450, F1: 0.6310\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:57<00:00,  4.71s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/200\n",
      "Train Loss: 1.3097, Accuracy: 0.6445\n",
      "Val   Loss: 1.3165, Accuracy: 0.6400, F1: 0.6382\n",
      "No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:57<00:00,  4.68s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/200\n",
      "Train Loss: 1.3027, Accuracy: 0.6382\n",
      "Val   Loss: 1.2931, Accuracy: 0.6700, F1: 0.6562\n",
      "No improvement for 3 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:57<00:00,  4.71s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/200\n",
      "Train Loss: 1.2890, Accuracy: 0.6771\n",
      "Val   Loss: 1.2469, Accuracy: 0.7150, F1: 0.7149\n",
      "✅ Best model saved at epoch 8 with F1: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:56<00:00,  4.68s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/200\n",
      "Train Loss: 1.2634, Accuracy: 0.6910\n",
      "Val   Loss: 1.2630, Accuracy: 0.6450, F1: 0.6384\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:56<00:00,  4.64s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/200\n",
      "Train Loss: 1.2636, Accuracy: 0.7023\n",
      "Val   Loss: 1.2217, Accuracy: 0.7500, F1: 0.7463\n",
      "✅ Best model saved at epoch 10 with F1: 0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:55<00:00,  4.62s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/200\n",
      "Train Loss: 1.2711, Accuracy: 0.6935\n",
      "Val   Loss: 1.2306, Accuracy: 0.7400, F1: 0.7362\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:54<00:00,  4.60s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:28<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/200\n",
      "Train Loss: 1.2459, Accuracy: 0.7136\n",
      "Val   Loss: 1.2242, Accuracy: 0.7650, F1: 0.7633\n",
      "✅ Best model saved at epoch 12 with F1: 0.7633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:54<00:00,  4.58s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:27<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/200\n",
      "Train Loss: 1.2295, Accuracy: 0.7148\n",
      "Val   Loss: 1.1962, Accuracy: 0.7700, F1: 0.7700\n",
      "✅ Best model saved at epoch 13 with F1: 0.7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:54<00:00,  4.59s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:21<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/200\n",
      "Train Loss: 1.2080, Accuracy: 0.7349\n",
      "Val   Loss: 1.1900, Accuracy: 0.7900, F1: 0.7897\n",
      "✅ Best model saved at epoch 14 with F1: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:25<00:00,  3.42s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:20<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/200\n",
      "Train Loss: 1.2041, Accuracy: 0.7462\n",
      "Val   Loss: 1.1475, Accuracy: 0.8200, F1: 0.8200\n",
      "✅ Best model saved at epoch 15 with F1: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:22<00:00,  3.30s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:19<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/200\n",
      "Train Loss: 1.1992, Accuracy: 0.7513\n",
      "Val   Loss: 1.1988, Accuracy: 0.7500, F1: 0.7469\n",
      "No improvement for 1 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:18<00:00,  3.16s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:19<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/200\n",
      "Train Loss: 1.1922, Accuracy: 0.7701\n",
      "Val   Loss: 1.1764, Accuracy: 0.7800, F1: 0.7796\n",
      "No improvement for 2 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:18<00:00,  3.14s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:19<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/200\n",
      "Train Loss: 1.1942, Accuracy: 0.7613\n",
      "Val   Loss: 1.1524, Accuracy: 0.7800, F1: 0.7796\n",
      "No improvement for 3 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:19<00:00,  3.17s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:19<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/200\n",
      "Train Loss: 1.1775, Accuracy: 0.7663\n",
      "Val   Loss: 1.1661, Accuracy: 0.7700, F1: 0.7685\n",
      "No improvement for 4 epoch(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:43: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
      "Training: 100%|██████████| 25/25 [01:19<00:00,  3.19s/it]\n",
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:19<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/200\n",
      "Train Loss: 1.1702, Accuracy: 0.7814\n",
      "Val   Loss: 1.1447, Accuracy: 0.7750, F1: 0.7743\n",
      "No improvement for 5 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train/accuracy</td><td>▁▂▃▄▄▄▄▅▆▆▆▆▆▇▇▇█▇██</td></tr><tr><td>train/loss</td><td>█▆▆▅▅▄▄▄▃▃▃▃▂▂▂▂▁▂▁▁</td></tr><tr><td>val/accuracy</td><td>▄▁▄▅▃▃▄▅▃▆▆▆▇▇█▆▇▇▇▇</td></tr><tr><td>val/f1</td><td>▅▁▅▅▄▄▅▆▄▆▆▇▇▇█▆▇▇▇▇</td></tr><tr><td>val/loss</td><td>▇█▆▆▆▆▆▄▅▃▄▃▃▂▁▃▂▁▂▁</td></tr><tr><td>val/precision</td><td>▃▂▄▄▂▁▄▄▂▆▆▆▆▇█▆▇▆▆▆</td></tr><tr><td>val/recall</td><td>▄▁▄▅▃▃▄▅▃▆▆▆▇▇█▆▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_acc</td><td>0.82</td></tr><tr><td>best_val_f1</td><td>0.82</td></tr><tr><td>best_val_loss</td><td>1.14751</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>train/accuracy</td><td>0.78141</td></tr><tr><td>train/loss</td><td>1.1702</td></tr><tr><td>val/accuracy</td><td>0.775</td></tr><tr><td>val/f1</td><td>0.77432</td></tr><tr><td>val/loss</td><td>1.14474</td></tr><tr><td>val/precision</td><td>0.77963</td></tr><tr><td>val/recall</td><td>0.77563</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vae_resnet50_run1</strong> at: <a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung/runs/vudivok9' target=\"_blank\">https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung/runs/vudivok9</a><br> View project at: <a href='https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung' target=\"_blank\">https://wandb.ai/mahmudisnan18-binus-university/vae-classifier-lung</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250511_170910-vudivok9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "wandb.init(\n",
    "    project=\"vae-classifier-lung\",\n",
    "    name=\"vae_resnet50_run1\",\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"epochs\": 200,\n",
    "        \"latent_dim\": 512,\n",
    "        \"batch_size\": 32,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"model\": \"VAE_Classifier_resnet50\"\n",
    "    }\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VAE_Classifier(latent_dim=512, num_classes=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# --- Training Loop ---\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x_input, x_raw, labels in tqdm(loader, desc=\"Training\"):\n",
    "        x_input, x_raw, labels = x_input.to(device), x_raw.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            x_recon, mu, logvar, y_pred = model(x_input)\n",
    "            recon_loss = nn.functional.binary_cross_entropy_with_logits(x_recon, x_raw, reduction='mean')\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()) / x_input.size(0)\n",
    "            class_loss = nn.functional.cross_entropy(y_pred, labels)\n",
    "            loss = recon_loss + 0.0001 * kl_loss + class_loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss += loss.item() * x_input.size(0)\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# --- Validation Loop ---\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_input, x_raw, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            x_input, x_raw, labels = x_input.to(device), x_raw.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                x_recon, mu, logvar, y_pred = model(x_input)\n",
    "                recon_loss = nn.functional.binary_cross_entropy_with_logits(x_recon, x_raw, reduction='mean')\n",
    "                kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()) / x_input.size(0)\n",
    "                class_loss = nn.functional.cross_entropy(y_pred, labels)\n",
    "                loss = recon_loss + 0.0001 * kl_loss + class_loss\n",
    "\n",
    "            running_loss += loss.item() * x_input.size(0)\n",
    "            preds = torch.argmax(y_pred, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1, all_labels, all_preds\n",
    "\n",
    "# --- Training Configuration ---\n",
    "best_val_f1 = 0.0\n",
    "patience = 5\n",
    "counter = 0\n",
    "early_stop = False\n",
    "num_epochs = wandb.config.epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1, val_labels, val_preds = validate(model, test_loader)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train/loss\": train_loss,\n",
    "        \"train/accuracy\": train_acc,\n",
    "        \"val/loss\": val_loss,\n",
    "        \"val/accuracy\": val_acc,\n",
    "        \"val/precision\": val_prec,\n",
    "        \"val/recall\": val_rec,\n",
    "        \"val/f1\": val_f1\n",
    "    })\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        counter = 0\n",
    "\n",
    "        checkpoint = {\n",
    "            'epoch': best_epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc,\n",
    "            'val_precision': val_prec,\n",
    "            'val_recall': val_rec,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, \"best_model_resnet50_checkpoint.pt\")\n",
    "        print(f\"✅ Best model saved at epoch {best_epoch} with F1: {val_f1:.4f}\")\n",
    "\n",
    "        wandb.summary[\"best_epoch\"] = best_epoch\n",
    "        wandb.summary[\"best_val_f1\"] = best_val_f1\n",
    "        wandb.summary[\"best_val_acc\"] = val_acc\n",
    "        wandb.summary[\"best_val_loss\"] = val_loss\n",
    "\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement for {counter} epoch(s).\")\n",
    "        if counter >= patience:\n",
    "            early_stop = True\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a2aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_dim: 2304\n",
      "===> Best Model Info:\n",
      "Epoch        : 15\n",
      "Val Accuracy : 0.8200\n",
      "Val Precision: 0.8201\n",
      "Val Recall   : 0.8201\n",
      "Val F1-score : 0.8200\n",
      "Val Loss     : 1.1475\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = VAE_Classifier(latent_dim=512, num_classes=2)\n",
    "checkpoint = torch.load(\"best_model_resnet50_checkpoint.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"===> Best Model Info:\")\n",
    "print(f\"Epoch        : {checkpoint['epoch']}\")\n",
    "print(f\"Val Accuracy : {checkpoint['val_accuracy']:.4f}\")\n",
    "print(f\"Val Precision: {checkpoint['val_precision']:.4f}\")\n",
    "print(f\"Val Recall   : {checkpoint['val_recall']:.4f}\")\n",
    "print(f\"Val F1-score : {checkpoint['val_f1']:.4f}\")\n",
    "print(f\"Val Loss     : {checkpoint['val_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b519599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_input, x_raw, labels in test_loader:\n",
    "        x_input = x_input.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        x_recon, mu, logvar, y_pred = model(x_input, deterministic=True)\n",
    "        preds = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8058f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c583bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_dim: 2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/7 [00:00<?, ?it/s]C:\\Users\\BDSRC\\AppData\\Local\\Temp\\ipykernel_12820\\2973061307.py:67: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Validation: 100%|██████████| 7/7 [00:21<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===> Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.80      0.84      0.82       101\n",
      "     class_1       0.83      0.79      0.81        99\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n",
      "Accuracy Score: 0.815\n",
      "Val F1-score  : 0.8147730970438787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Pastikan model dan checkpoint sudah diload:\n",
    "model = VAE_Classifier(latent_dim=512, num_classes=2)\n",
    "checkpoint = torch.load(\"best_model_resnet50_checkpoint.pt\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Evaluasi ulang di test_loader (atau val_loader)\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_labels, val_preds = validate(model, test_loader)\n",
    "\n",
    "# Konversi ke list int\n",
    "val_labels = np.array(val_labels).astype(int).tolist()\n",
    "val_preds = np.array(val_preds).astype(int).tolist()\n",
    "\n",
    "# Cetak classification report\n",
    "print(\"\\n===> Classification Report:\")\n",
    "print(classification_report(val_labels, val_preds, target_names=[\"class_0\", \"class_1\"], zero_division=0))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(val_labels, val_preds))\n",
    "print(f\"Val F1-score  :\", val_f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViTlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
